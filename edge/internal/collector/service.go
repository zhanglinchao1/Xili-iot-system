/*
 * æ•°æ®é‡‡é›†æœåŠ¡
 * è´Ÿè´£ä¼ æ„Ÿå™¨æ•°æ®çš„é‡‡é›†ã€å­˜å‚¨å’Œå¤„ç†
 */
package collector

import (
	"context"
	"encoding/json"
	"fmt"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/edge/storage-cabinet/internal/config"
	"github.com/edge/storage-cabinet/internal/device"
	"github.com/edge/storage-cabinet/internal/storage"
	"github.com/edge/storage-cabinet/pkg/models"
	"go.uber.org/zap"
)

// Service æ•°æ®é‡‡é›†æœåŠ¡
type Service struct {
	logger          *zap.Logger
	db              *storage.SQLiteDB
	deviceManager   *device.Manager
	rs485Collector  *RS485Collector
	dataChan        chan *models.SensorData
	alertChan       chan *models.Alert
	bufferSize      int
	batchSize       int
	collectInterval time.Duration
	syncInterval    time.Duration
	retentionDays   int
	thresholds      map[models.SensorType]*models.SensorThreshold
	mu              sync.RWMutex
	running         bool
	stopChan        chan struct{}
	wg              sync.WaitGroup
	cloudSync       CloudSyncInterface      // äº‘ç«¯åŒæ­¥æ¥å£ï¼ˆç”¨äºå³æ—¶å‘Šè­¦ä¸ŠæŠ¥ï¼‰
	alertPublisher  AlertPublisherInterface // MQTTå‘Šè­¦å‘å¸ƒå™¨ï¼ˆç”¨äºå®æ—¶æ¨é€ï¼‰
}

// CloudSyncInterface å®šä¹‰äº‘ç«¯åŒæ­¥æ¥å£ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰
type CloudSyncInterface interface {
	ReportAlertImmediately(alert *models.Alert) error
}

// AlertPublisherInterface å®šä¹‰å‘Šè­¦MQTTå‘å¸ƒæ¥å£
type AlertPublisherInterface interface {
	PublishAlert(alert *models.Alert) error
	IsEnabled() bool
}

// NewService åˆ›å»ºæ•°æ®é‡‡é›†æœåŠ¡
func NewService(cfg config.DataConfig, alertCfg config.AlertConfig, db *storage.SQLiteDB, deviceManager *device.Manager, logger *zap.Logger) *Service {
	return &Service{
		logger:          logger,
		db:              db,
		deviceManager:   deviceManager,
		dataChan:        make(chan *models.SensorData, cfg.BufferSize),
		alertChan:       make(chan *models.Alert, 1000),
		bufferSize:      cfg.BufferSize,
		batchSize:       cfg.BatchSize,
		collectInterval: cfg.CollectInterval,
		syncInterval:    cfg.SyncInterval,
		retentionDays:   cfg.RetentionDays,
		thresholds:      initThresholdsFromConfig(alertCfg),
		stopChan:        make(chan struct{}),
	}
}

// SetCloudSync è®¾ç½®äº‘ç«¯åŒæ­¥æ¥å£ï¼ˆç”¨äºå³æ—¶å‘Šè­¦ä¸ŠæŠ¥ï¼‰
func (s *Service) SetCloudSync(cloudSync CloudSyncInterface) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.cloudSync = cloudSync
	s.logger.Info("Cloud sync interface set for immediate alert reporting")
}

// SetAlertPublisher è®¾ç½®å‘Šè­¦MQTTå‘å¸ƒå™¨ï¼ˆç”¨äºå®æ—¶æ¨é€ï¼‰
func (s *Service) SetAlertPublisher(publisher AlertPublisherInterface) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.alertPublisher = publisher
	s.logger.Info("Alert MQTT publisher set for real-time alert notification")
}

// initThresholdsFromConfig ä»é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¼ æ„Ÿå™¨é˜ˆå€¼
func initThresholdsFromConfig(alertCfg config.AlertConfig) map[models.SensorType]*models.SensorThreshold {
	if !alertCfg.Enabled {
		return map[models.SensorType]*models.SensorThreshold{}
	}

	t := alertCfg.Thresholds
	return map[models.SensorType]*models.SensorThreshold{
		models.SensorCO2: {
			SensorType: models.SensorCO2,
			MinValue:   0,
			MaxValue:   t.CO2Max,
			Unit:       "ppm",
		},
		models.SensorCO: {
			SensorType: models.SensorCO,
			MinValue:   0,
			MaxValue:   t.COMax,
			Unit:       "ppm",
		},
		models.SensorSmoke: {
			SensorType: models.SensorSmoke,
			MinValue:   0,
			MaxValue:   t.SmokeMax,
			Unit:       "ppm",
		},
		models.SensorLiquidLevel: {
			SensorType: models.SensorLiquidLevel,
			MinValue:   t.LiquidLevelMin,
			MaxValue:   t.LiquidLevelMax,
			Unit:       "mm",
		},
		models.SensorConductivity: {
			SensorType: models.SensorConductivity,
			MinValue:   t.ConductivityMin,
			MaxValue:   t.ConductivityMax,
			Unit:       "mS/cm",
		},
		models.SensorTemperature: {
			SensorType: models.SensorTemperature,
			MinValue:   t.TemperatureMin,
			MaxValue:   t.TemperatureMax,
			Unit:       "Â°C",
		},
		models.SensorFlow: {
			SensorType: models.SensorFlow,
			MinValue:   t.FlowMin,
			MaxValue:   t.FlowMax,
			Unit:       "L/min",
		},
	}
}

// SetRS485Collector è®¾ç½®RS485é‡‡é›†å™¨
func (s *Service) SetRS485Collector(rs485 *RS485Collector) {
	s.rs485Collector = rs485
}

// Start å¯åŠ¨æ•°æ®é‡‡é›†
func (s *Service) Start(ctx context.Context) error {
	s.mu.Lock()
	if s.running {
		s.mu.Unlock()
		return fmt.Errorf("collector already running")
	}
	s.running = true
	s.mu.Unlock()

	// å¯åŠ¨RS485é‡‡é›†å™¨
	if s.rs485Collector != nil {
		if err := s.rs485Collector.Start(); err != nil {
			return fmt.Errorf("failed to start RS485 collector: %w", err)
		}

		// å¯åŠ¨RS485æ•°æ®æ¥æ”¶åç¨‹
		s.wg.Add(1)
		go s.receiveRS485Data()
	}

	// å¯åŠ¨æ•°æ®å¤„ç†åç¨‹
	s.wg.Add(1)
	go s.processData()

	// å¯åŠ¨æ‰¹é‡å­˜å‚¨åç¨‹
	s.wg.Add(1)
	go s.batchStore()

	// å¯åŠ¨å‘Šè­¦å¤„ç†åç¨‹
	s.wg.Add(1)
	go s.processAlerts()

	// å¯åŠ¨æ•°æ®æ¸…ç†åç¨‹
	s.wg.Add(1)
	go s.cleanupOldData()

	s.logger.Info("Data collector started")
	return nil
}

// Stop åœæ­¢æ•°æ®é‡‡é›†
func (s *Service) Stop() {
	s.mu.Lock()
	if !s.running {
		s.mu.Unlock()
		return
	}
	s.running = false
	s.mu.Unlock()

	// åœæ­¢RS485é‡‡é›†å™¨
	if s.rs485Collector != nil {
		s.rs485Collector.Stop()
	}

	close(s.stopChan)
	s.wg.Wait()

	s.logger.Info("Data collector stopped")
}

// CollectData æ¥æ”¶ä¼ æ„Ÿå™¨æ•°æ®
func (s *Service) CollectData(req *models.DataCollectRequest) error {
	// åˆ›å»ºä¼ æ„Ÿå™¨æ•°æ®è®°å½•
	data := &models.SensorData{
		DeviceID:   req.DeviceID,
		SensorType: req.SensorType,
		Value:      req.Value,
		Unit:       req.Unit,
		Timestamp:  req.Timestamp,
		Quality:    req.Quality,
		Synced:     false,
	}

	// æ•°æ®è´¨é‡æ£€æŸ¥
	if data.Quality == 0 {
		data.Quality = 100 // é»˜è®¤è´¨é‡ä¸º100
	}

	// æ—¶é—´æˆ³æ£€æŸ¥
	if data.Timestamp.IsZero() {
		data.Timestamp = time.Now()
	}

	// æ£€æŸ¥æ•°æ®æ˜¯å¦è¶…å‡ºé˜ˆå€¼
	if err := s.checkThreshold(data); err != nil {
		s.logger.Warn("Data threshold exceeded",
			zap.String("device_id", data.DeviceID),
			zap.String("sensor_type", string(data.SensorType)),
			zap.Float64("value", data.Value),
			zap.Error(err))
	}

	// å‘é€åˆ°æ•°æ®é€šé“
	select {
	case s.dataChan <- data:
		s.logger.Debug("Data collected",
			zap.String("device_id", data.DeviceID),
			zap.String("sensor_type", string(data.SensorType)),
			zap.Float64("value", data.Value))
	default:
		s.logger.Warn("Data channel full, dropping data",
			zap.String("device_id", data.DeviceID))
		return fmt.Errorf("data buffer full")
	}

	return nil
}

// receiveRS485Data æ¥æ”¶RS485æ•°æ®
func (s *Service) receiveRS485Data() {
	defer s.wg.Done()

	if s.rs485Collector == nil {
		return
	}

	dataChan := s.rs485Collector.GetDataChannel()

	for {
		select {
		case <-s.stopChan:
			return
		case frame := <-dataChan:
			if frame == nil {
				continue
			}

			// è½¬æ¢ä¸ºä¼ æ„Ÿå™¨æ•°æ®
			data := &models.SensorData{
				DeviceID:   frame.DeviceID,
				SensorType: frame.SensorType,
				Value:      frame.Value,
				Unit:       frame.Unit,
				Timestamp:  frame.Timestamp,
				Quality:    frame.Quality,
				Synced:     false,
			}

			// æ£€æŸ¥é˜ˆå€¼å¹¶å‘é€
			if err := s.checkThreshold(data); err != nil {
				s.logger.Warn("RS485 data threshold exceeded",
					zap.String("device_id", data.DeviceID),
					zap.Error(err))
			}

			select {
			case s.dataChan <- data:
			default:
				s.logger.Warn("Data channel full from RS485")
			}
		}
	}
}

// processData å¤„ç†æ•°æ®
func (s *Service) processData() {
	defer s.wg.Done()

	batch := make([]*models.SensorData, 0, s.batchSize)
	ticker := time.NewTicker(5 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-s.stopChan:
			// ä¿å­˜å‰©ä½™æ•°æ®
			if len(batch) > 0 {
				s.storeBatch(batch)
			}
			return

		case data := <-s.dataChan:
			batch = append(batch, data)

			// æ‰¹é‡å­˜å‚¨
			if len(batch) >= s.batchSize {
				s.storeBatch(batch)
				batch = make([]*models.SensorData, 0, s.batchSize)
			}

		case <-ticker.C:
			// å®šæ—¶å­˜å‚¨
			if len(batch) > 0 {
				s.storeBatch(batch)
				batch = make([]*models.SensorData, 0, s.batchSize)
			}
		}
	}
}

// batchStore æ‰¹é‡å­˜å‚¨åç¨‹
func (s *Service) batchStore() {
	defer s.wg.Done()
	// è¿™ä¸ªåç¨‹å¯ä»¥ç”¨äºé¢å¤–çš„æ‰¹é‡æ“ä½œæˆ–ç»Ÿè®¡
}

// storeBatch æ‰¹é‡å­˜å‚¨æ•°æ®
func (s *Service) storeBatch(batch []*models.SensorData) {
	if len(batch) == 0 {
		return
	}

	tx, err := s.db.Begin()
	if err != nil {
		s.logger.Error("Failed to begin transaction", zap.Error(err))
		return
	}
	defer tx.Rollback()

	query := `
		INSERT INTO sensor_data (device_id, sensor_type, value, unit, timestamp, quality, synced)
		VALUES (?, ?, ?, ?, ?, ?, ?)
	`
	stmt, err := tx.Prepare(query)
	if err != nil {
		s.logger.Error("Failed to prepare statement", zap.Error(err))
		return
	}
	defer stmt.Close()

	for _, data := range batch {
		_, err := stmt.Exec(
			data.DeviceID, data.SensorType, data.Value,
			data.Unit, data.Timestamp, data.Quality, data.Synced,
		)
		if err != nil {
			s.logger.Error("Failed to insert data",
				zap.String("device_id", data.DeviceID),
				zap.Error(err))
			continue
		}
	}

	if err := tx.Commit(); err != nil {
		s.logger.Error("Failed to commit transaction", zap.Error(err))
		return
	}

	s.logger.Debug("Batch stored", zap.Int("count", len(batch)))
}

// checkThreshold æ£€æŸ¥æ•°æ®é˜ˆå€¼
func (s *Service) checkThreshold(data *models.SensorData) error {
	threshold, exists := s.thresholds[data.SensorType]
	if !exists {
		return nil
	}

	var alertType models.AlertType
	var severity models.Severity
	var message string

	// æ£€æŸ¥ä¸Šä¸‹é™
	if data.Value < threshold.MinValue {
		switch data.SensorType {
		case models.SensorLiquidLevel:
			alertType = models.AlertLiquidLevelLow
			message = fmt.Sprintf("æ¶²ä½è¿‡ä½: %.2f%s (ä¸‹é™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MinValue, threshold.Unit)
		case models.SensorTemperature:
			alertType = models.AlertTemperatureLow
			message = fmt.Sprintf("æ¸©åº¦è¿‡ä½: %.2f%s (ä¸‹é™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MinValue, threshold.Unit)
		case models.SensorFlow:
			alertType = models.AlertFlowAbnormal
			message = fmt.Sprintf("æµé€Ÿè¿‡ä½: %.2f%s (ä¸‹é™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MinValue, threshold.Unit)
		case models.SensorConductivity: // ç”µå¯¼ç‡
			alertType = models.AlertConductivityAbnormal
			message = fmt.Sprintf("ç”µå¯¼ç‡è¿‡ä½: %.2f%s (ä¸‹é™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MinValue, threshold.Unit)
		default:
			return nil
		}
		severity = models.SeverityMedium
	} else if data.Value > threshold.MaxValue {
		switch data.SensorType {
		case models.SensorCO2:
			alertType = models.AlertCO2High
			message = fmt.Sprintf("CO2æµ“åº¦è¶…æ ‡: %.2fppm (ä¸Šé™: %.2fppm)",
				data.Value, threshold.MaxValue)
			severity = models.SeverityHigh
		case models.SensorCO:
			alertType = models.AlertCOHigh
			message = fmt.Sprintf("COæµ“åº¦è¶…æ ‡: %.2fppm (ä¸Šé™: %.2fppm)",
				data.Value, threshold.MaxValue)
			severity = models.SeverityCritical // COæ›´å±é™©
		case models.SensorSmoke:
			alertType = models.AlertSmokeDetected
			message = fmt.Sprintf("æ£€æµ‹åˆ°çƒŸé›¾: %.2fppm (ä¸Šé™: %.2fppm)",
				data.Value, threshold.MaxValue)
			severity = models.SeverityCritical
		case models.SensorLiquidLevel:
			alertType = models.AlertLiquidLevelHigh
			message = fmt.Sprintf("æ¶²ä½è¿‡é«˜: %.2f%s (ä¸Šé™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MaxValue, threshold.Unit)
			severity = models.SeverityMedium
		case models.SensorTemperature:
			alertType = models.AlertTemperatureHigh
			message = fmt.Sprintf("æ¸©åº¦è¿‡é«˜: %.2f%s (ä¸Šé™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MaxValue, threshold.Unit)
			severity = models.SeverityHigh
		case models.SensorFlow:
			alertType = models.AlertFlowAbnormal
			message = fmt.Sprintf("æµé€Ÿè¿‡é«˜: %.2f%s (ä¸Šé™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MaxValue, threshold.Unit)
			severity = models.SeverityMedium
		case models.SensorConductivity: // ç”µå¯¼ç‡
			alertType = models.AlertConductivityAbnormal
			message = fmt.Sprintf("ç”µå¯¼ç‡è¿‡é«˜: %.2f%s (ä¸Šé™: %.2f%s)",
				data.Value, threshold.Unit, threshold.MaxValue, threshold.Unit)
			severity = models.SeverityMedium
		default:
			return nil
		}
	} else {
		return nil // æ•°æ®æ­£å¸¸
	}

	// åˆ›å»ºå‘Šè­¦
	valuePtr := data.Value
	thresholdPtr := threshold.MaxValue
	alert := &models.Alert{
		DeviceID:  data.DeviceID,
		AlertType: string(alertType),
		Severity:  string(severity),
		Message:   message,
		Value:     &valuePtr,
		Threshold: &thresholdPtr,
		Timestamp: time.Now(),
		Resolved:  false,
	}

	// å‘é€å‘Šè­¦
	select {
	case s.alertChan <- alert:
		s.logger.Warn("Alert triggered",
			zap.String("device_id", data.DeviceID),
			zap.String("alert_type", string(alertType)),
			zap.String("severity", string(severity)),
			zap.String("message", message))
	default:
		s.logger.Error("Alert channel full")
	}

	return fmt.Errorf("%s", message)
}

// processAlerts å¤„ç†å‘Šè­¦
func (s *Service) processAlerts() {
	defer s.wg.Done()

	for {
		select {
		case <-s.stopChan:
			return
		case alert := <-s.alertChan:
			if alert == nil {
				continue
			}

			// ä¿å­˜å‘Šè­¦åˆ°æ•°æ®åº“
			if err := s.saveAlert(alert); err != nil {
				s.logger.Error("Failed to save alert", zap.Error(err))
			}

			// TODO: å‘é€å‘Šè­¦é€šçŸ¥ï¼ˆé‚®ä»¶ã€çŸ­ä¿¡ã€æ¨é€ç­‰ï¼‰
		}
	}
}

// saveAlert ä¿å­˜å‘Šè­¦ï¼ˆå¸¦å»é‡ï¼šåŒä¸€è®¾å¤‡åŒä¸€ç±»å‹çš„æœªè§£å†³å‘Šè­¦ä¸é‡å¤åˆ›å»ºï¼‰
func (s *Service) saveAlert(alert *models.Alert) error {
	s.logger.Debug("saveAlert called",
		zap.String("device_id", alert.DeviceID),
		zap.String("alert_type", alert.AlertType),
		zap.String("severity", alert.Severity))

	// å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒçš„æœªè§£å†³å‘Šè­¦
	checkQuery := `
		SELECT id, timestamp FROM alerts
		WHERE device_id = ? AND alert_type = ? AND resolved = 0
		ORDER BY timestamp DESC LIMIT 1
	`
	var existingID int64
	var existingTimestamp time.Time
	err := s.db.QueryRow(checkQuery, alert.DeviceID, alert.AlertType).Scan(&existingID, &existingTimestamp)

	s.logger.Debug("Check existing alert result",
		zap.Error(err),
		zap.Int64("existing_id", existingID))

	if err == nil {
		// å­˜åœ¨æœªè§£å†³çš„å‘Šè­¦ï¼Œæ›´æ–°æ—¶é—´æˆ³å’Œæ•°å€¼ï¼ˆè¡¨ç¤ºå‘Šè­¦ä»åœ¨æŒç»­ï¼‰
		// åŒæ—¶é‡ç½®synced_atä¸ºNULLï¼Œç¡®ä¿æ›´æ–°åçš„å‘Šè­¦ä¼šè¢«åŒæ­¥åˆ°Cloudç«¯
		updateQuery := `
			UPDATE alerts
			SET timestamp = ?, message = ?, value = ?, threshold = ?, severity = ?, synced_at = NULL
			WHERE id = ?
		`
		_, err = s.db.Exec(updateQuery,
			alert.Timestamp, alert.Message, alert.Value, alert.Threshold, alert.Severity, existingID)
		if err == nil {
			s.logger.Debug("Updated existing alert",
				zap.String("device_id", alert.DeviceID),
				zap.String("alert_type", alert.AlertType),
				zap.Int64("alert_id", existingID))

			// æ›´æ–°å‘Šè­¦IDï¼Œç”¨äºä¸ŠæŠ¥
			alert.ID = existingID

			// ä¼˜å…ˆé€šè¿‡MQTTå®æ—¶æ¨é€å‘Šè­¦ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å‘Šè­¦æ›´æ–°ï¼‰
			s.mu.RLock()
			alertPublisher := s.alertPublisher
			cloudSync := s.cloudSync
			s.mu.RUnlock()

			go func() {
				mqttSuccess := false

				// å°è¯•MQTTå‘å¸ƒ
				if alertPublisher != nil && alertPublisher.IsEnabled() {
					if err := alertPublisher.PublishAlert(alert); err == nil {
						mqttSuccess = true
						// MQTTå‘å¸ƒæˆåŠŸï¼Œæ ‡è®°ä¸ºå·²åŒæ­¥
						s.db.Exec("UPDATE alerts SET synced_at = ? WHERE id = ?", time.Now(), existingID)
						s.logger.Debug("Alert published via MQTT and marked as synced")
					} else {
						s.logger.Debug("MQTT alert publish failed, will use HTTP fallback", zap.Error(err))
					}
				}

				// MQTTå¤±è´¥æ—¶ï¼Œä½¿ç”¨HTTPä½œä¸ºå…œåº•
				if !mqttSuccess && cloudSync != nil {
					if err := cloudSync.ReportAlertImmediately(alert); err != nil {
						s.logger.Debug("HTTP alert report also failed (will retry in batch sync)", zap.Error(err))
					}
				}
			}()
		}
		return err
	}

	// ä¸å­˜åœ¨æœªè§£å†³å‘Šè­¦ï¼Œåˆ›å»ºæ–°å‘Šè­¦
	insertQuery := `
		INSERT INTO alerts (device_id, alert_type, severity, message, value, threshold, timestamp, resolved)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?)
	`
	result, err := s.db.Exec(insertQuery,
		alert.DeviceID, alert.AlertType, alert.Severity, alert.Message,
		alert.Value, alert.Threshold, alert.Timestamp, alert.Resolved,
	)
	if err == nil {
		// è·å–æ–°åˆ›å»ºçš„å‘Šè­¦ID
		newAlertID, _ := result.LastInsertId()
		alert.ID = newAlertID

		s.logger.Info("Created new alert",
			zap.String("device_id", alert.DeviceID),
			zap.String("alert_type", alert.AlertType),
			zap.String("severity", alert.Severity),
			zap.Int64("alert_id", newAlertID))

		// ä¼˜å…ˆé€šè¿‡MQTTå®æ—¶æ¨é€å‘Šè­¦ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å‘Šè­¦åˆ›å»ºï¼‰
		s.mu.RLock()
		alertPublisher := s.alertPublisher
		cloudSync := s.cloudSync
		s.mu.RUnlock()

		go func() {
			mqttSuccess := false

			// å°è¯•MQTTå‘å¸ƒ
			if alertPublisher != nil && alertPublisher.IsEnabled() {
				if err := alertPublisher.PublishAlert(alert); err == nil {
					mqttSuccess = true
					// MQTTå‘å¸ƒæˆåŠŸï¼Œæ ‡è®°ä¸ºå·²åŒæ­¥
					s.db.Exec("UPDATE alerts SET synced_at = ? WHERE id = ?", time.Now(), newAlertID)
					s.logger.Debug("Alert published via MQTT and marked as synced",
						zap.Int64("alert_id", newAlertID))
				} else {
					s.logger.Debug("MQTT alert publish failed, will use HTTP fallback", zap.Error(err))
				}
			}

			// MQTTå¤±è´¥æ—¶ï¼Œä½¿ç”¨HTTPä½œä¸ºå…œåº•
			if !mqttSuccess && cloudSync != nil {
				if err := cloudSync.ReportAlertImmediately(alert); err != nil {
					s.logger.Debug("HTTP alert report also failed (will retry in batch sync)", zap.Error(err))
				}
			}
		}()
	}
	return err
}

// GetRecentData è·å–æœ€è¿‘çš„æ•°æ®
func (s *Service) GetRecentData(deviceID string, limit int) ([]*models.SensorData, error) {
	query := `
		SELECT id, device_id, sensor_type, value, unit, timestamp, quality, synced
		FROM sensor_data
		WHERE device_id = ?
		ORDER BY timestamp DESC
		LIMIT ?
	`

	rows, err := s.db.Query(query, deviceID, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var data []*models.SensorData
	for rows.Next() {
		d := &models.SensorData{}
		err := rows.Scan(
			&d.ID, &d.DeviceID, &d.SensorType, &d.Value,
			&d.Unit, &d.Timestamp, &d.Quality, &d.Synced,
		)
		if err != nil {
			continue
		}
		data = append(data, d)
	}

	return data, nil
}

// GetStatistics è·å–æ•°æ®ç»Ÿè®¡
func (s *Service) GetStatistics(deviceID string, sensorType models.SensorType, startTime, endTime time.Time) (*models.DataStatistics, error) {
	// æ„å»ºåŠ¨æ€æŸ¥è¯¢æ¡ä»¶
	query := `
		SELECT
			COUNT(*) as count,
			COALESCE(MIN(value), 0) as min_value,
			COALESCE(MAX(value), 0) as max_value,
			COALESCE(AVG(value), 0) as avg_value
		FROM sensor_data
		WHERE timestamp BETWEEN ? AND ?
	`

	args := []interface{}{startTime, endTime}

	// å¯é€‰æ¡ä»¶ï¼šè®¾å¤‡ID
	if deviceID != "" {
		query += " AND device_id = ?"
		args = append(args, deviceID)
	}

	// å¯é€‰æ¡ä»¶ï¼šä¼ æ„Ÿå™¨ç±»å‹
	if sensorType != "" {
		query += " AND sensor_type = ?"
		args = append(args, sensorType)
	}

	stats := &models.DataStatistics{
		DeviceID:   deviceID,
		SensorType: sensorType,
		StartTime:  startTime,
		EndTime:    endTime,
	}

	err := s.db.QueryRow(query, args...).Scan(
		&stats.Count, &stats.MinValue, &stats.MaxValue, &stats.AvgValue,
	)
	if err != nil {
		return nil, err
	}

	return stats, nil
}

// QueryData æŸ¥è¯¢å†å²æ•°æ®
func (s *Service) QueryData(deviceID, sensorType, startTime, endTime string, page, limit int) ([]*models.SensorData, int64, error) {
	// æ„å»ºæŸ¥è¯¢æ¡ä»¶
	var conditions []string
	var args []interface{}

	if deviceID != "" {
		conditions = append(conditions, "device_id = ?")
		args = append(args, deviceID)
	}

	if sensorType != "" {
		conditions = append(conditions, "sensor_type = ?")
		args = append(args, sensorType)
	}

	if startTime != "" {
		conditions = append(conditions, "timestamp >= ?")
		args = append(args, startTime)
	}

	if endTime != "" {
		conditions = append(conditions, "timestamp <= ?")
		args = append(args, endTime)
	}

	whereClause := ""
	if len(conditions) > 0 {
		whereClause = "WHERE " + strings.Join(conditions, " AND ")
	}

	// æŸ¥è¯¢æ€»æ•°
	countQuery := fmt.Sprintf("SELECT COUNT(*) FROM sensor_data %s", whereClause)
	var total int64
	err := s.db.QueryRow(countQuery, args...).Scan(&total)
	if err != nil {
		return nil, 0, fmt.Errorf("failed to count data: %w", err)
	}

	// æŸ¥è¯¢æ•°æ®
	offset := (page - 1) * limit
	dataQuery := fmt.Sprintf(`
		SELECT id, device_id, sensor_type, value, unit, timestamp, quality, synced 
		FROM sensor_data %s 
		ORDER BY timestamp DESC 
		LIMIT ? OFFSET ?`, whereClause)

	args = append(args, limit, offset)
	rows, err := s.db.Query(dataQuery, args...)
	if err != nil {
		return nil, 0, fmt.Errorf("failed to query data: %w", err)
	}
	defer rows.Close()

	var data []*models.SensorData
	for rows.Next() {
		var d models.SensorData
		err := rows.Scan(&d.ID, &d.DeviceID, &d.SensorType, &d.Value, &d.Unit, &d.Timestamp, &d.Quality, &d.Synced)
		if err != nil {
			return nil, 0, fmt.Errorf("failed to scan data: %w", err)
		}
		data = append(data, &d)
	}

	return data, total, nil
}

// GetStatisticsByPeriod æ ¹æ®æ—¶é—´æ®µè·å–ç»Ÿè®¡æ•°æ®
func (s *Service) GetStatisticsByPeriod(deviceID, sensorType, period string) (*models.DataStatistics, error) {
	// è§£ææ—¶é—´æ®µ
	var startTime time.Time
	switch period {
	case "1h":
		startTime = time.Now().Add(-1 * time.Hour)
	case "24h":
		startTime = time.Now().Add(-24 * time.Hour)
	case "7d":
		startTime = time.Now().Add(-7 * 24 * time.Hour)
	case "30d":
		startTime = time.Now().Add(-30 * 24 * time.Hour)
	default:
		startTime = time.Now().Add(-24 * time.Hour)
	}

	return s.GetStatistics(deviceID, models.SensorType(sensorType), startTime, time.Now())
}

// ListAlerts è·å–å‘Šè­¦åˆ—è¡¨
func (s *Service) ListAlerts(page, limit int, severity, resolved string) ([]*models.Alert, int64, error) {
	// æ„å»ºæŸ¥è¯¢æ¡ä»¶
	var conditions []string
	var args []interface{}

	if severity != "" {
		conditions = append(conditions, "severity = ?")
		args = append(args, severity)
	}

	if resolved != "" {
		resolvedBool, _ := strconv.ParseBool(resolved)
		conditions = append(conditions, "resolved = ?")
		args = append(args, resolvedBool)
	}

	whereClause := ""
	if len(conditions) > 0 {
		whereClause = "WHERE " + strings.Join(conditions, " AND ")
	}

	// æŸ¥è¯¢æ€»æ•°
	countQuery := fmt.Sprintf("SELECT COUNT(*) FROM alerts %s", whereClause)
	var total int64
	err := s.db.QueryRow(countQuery, args...).Scan(&total)
	if err != nil {
		return nil, 0, fmt.Errorf("failed to count alerts: %w", err)
	}

	// æŸ¥è¯¢å‘Šè­¦
	offset := (page - 1) * limit
	alertQuery := fmt.Sprintf(`
		SELECT id, device_id, alert_type, severity, message, value, threshold, timestamp, resolved, resolved_at 
		FROM alerts %s 
		ORDER BY timestamp DESC 
		LIMIT ? OFFSET ?`, whereClause)

	args = append(args, limit, offset)
	rows, err := s.db.Query(alertQuery, args...)
	if err != nil {
		return nil, 0, fmt.Errorf("failed to query alerts: %w", err)
	}
	defer rows.Close()

	var alerts []*models.Alert
	for rows.Next() {
		var alert models.Alert
		err := rows.Scan(&alert.ID, &alert.DeviceID, &alert.AlertType, &alert.Severity,
			&alert.Message, &alert.Value, &alert.Threshold, &alert.Timestamp,
			&alert.Resolved, &alert.ResolvedAt)
		if err != nil {
			return nil, 0, fmt.Errorf("failed to scan alert: %w", err)
		}
		alerts = append(alerts, &alert)
	}

	return alerts, total, nil
}

// CreateAlert åˆ›å»ºå‘Šè­¦
func (s *Service) CreateAlert(alert *models.Alert) error {
	query := `
		INSERT INTO alerts (device_id, alert_type, severity, message, value, threshold, timestamp, resolved)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?)`

	_, err := s.db.Exec(query, alert.DeviceID, alert.AlertType, alert.Severity,
		alert.Message, alert.Value, alert.Threshold, alert.Timestamp, alert.Resolved)
	if err != nil {
		return fmt.Errorf("failed to create alert: %w", err)
	}

	s.logger.Info("Alert created",
		zap.String("device_id", alert.DeviceID),
		zap.String("type", alert.AlertType),
		zap.String("severity", alert.Severity))

	return nil
}

// ResolveAlert è§£å†³å‘Šè­¦ï¼ˆå¯è¢«Cloudå‘½ä»¤ä¸‹å‘æˆ–æœ¬åœ°APIè°ƒç”¨ï¼‰
func (s *Service) ResolveAlert(alertID int64) error {
	now := time.Now()
	// é‡ç½®synced_atä¸ºNULL,è§¦å‘é‡æ–°åŒæ­¥åˆ°Cloudç«¯
	query := `UPDATE alerts SET resolved = ?, resolved_at = ?, synced_at = NULL WHERE id = ?`

	result, err := s.db.Exec(query, true, now, alertID)
	if err != nil {
		return fmt.Errorf("failed to resolve alert: %w", err)
	}

	rowsAffected, err := result.RowsAffected()
	if err != nil {
		return fmt.Errorf("failed to get rows affected: %w", err)
	}

	if rowsAffected == 0 {
		return fmt.Errorf("alert not found: %d", alertID)
	}

	s.logger.Info("âœ… å‘Šè­¦å·²è§£å†³", zap.Int64("alert_id", alertID))
	return nil
}

// SaveSensorData ä¿å­˜å•ä¸ªä¼ æ„Ÿå™¨æ•°æ®ï¼ˆMQTT è°ƒç”¨ - ç«‹å³å†™å…¥ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
func (s *Service) SaveSensorData(mqttData interface{}) error {
	// å®šä¹‰MQTTæ•°æ®ç»“æ„ï¼ˆåŒ¹é…mqtt.SensorDataï¼‰
	type mqttSensorData struct {
		DeviceID   string    `json:"device_id"`
		SensorType string    `json:"sensor_type"`
		Value      float64   `json:"value"`
		Unit       string    `json:"unit"`
		Quality    int       `json:"quality"`
		Timestamp  time.Time `json:"timestamp"`
	}

	// å…ˆè½¬æ¢ä¸ºé€šç”¨ç»“æ„
	jsonBytes, err := json.Marshal(mqttData)
	if err != nil {
		return fmt.Errorf("failed to marshal mqtt data: %w", err)
	}

	var mqttD mqttSensorData
	if err := json.Unmarshal(jsonBytes, &mqttD); err != nil {
		return fmt.Errorf("failed to unmarshal mqtt data: %w", err)
	}

	// è½¬æ¢ä¸º models.SensorData
	data := &models.SensorData{
		DeviceID:   mqttD.DeviceID,
		SensorType: models.SensorType(mqttD.SensorType),
		Value:      mqttD.Value,
		Unit:       mqttD.Unit,
		Timestamp:  mqttD.Timestamp,
		Quality:    mqttD.Quality,
		Synced:     false,
	}

	// æ£€æŸ¥é˜ˆå€¼
	if err := s.checkThreshold(data); err != nil {
		s.logger.Warn("MQTT data threshold exceeded",
			zap.String("device_id", data.DeviceID),
			zap.Error(err))
	}

	// MQTTæ•°æ®ç«‹å³å†™å…¥æ•°æ®åº“ï¼ˆä¸èµ°æ‰¹é‡é€šé“ï¼‰
	// ä¼˜åŠ¿ï¼š0å»¶è¿Ÿï¼Œå‰ç«¯å¯ç«‹å³æŸ¥è¯¢åˆ°æœ€æ–°æ•°æ®
	if err := s.saveSensorDataImmediate(data); err != nil {
		s.logger.Error("Failed to save MQTT sensor data immediately",
			zap.String("device_id", data.DeviceID),
			zap.Error(err))
		return fmt.Errorf("failed to save immediately: %w", err)
	}

	// æ›´æ–°è®¾å¤‡æœ€åæ´»è·ƒæ—¶é—´ï¼ˆæ ‡è®°ä¸ºåœ¨çº¿ï¼‰
	// åªè¦è®¾å¤‡å‘é€ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå°±è®¤ä¸ºè®¾å¤‡åœ¨çº¿
	if err := s.deviceManager.UpdateLastSeen(data.DeviceID); err != nil {
		s.logger.Warn("Failed to update device last seen time",
			zap.String("device_id", data.DeviceID),
			zap.Error(err))
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºæ•°æ®å·²ç»ä¿å­˜æˆåŠŸ
	}

	s.logger.Info("âœ… ä¼ æ„Ÿå™¨æ•°æ®å·²ä¿å­˜",
		zap.String("device_id", data.DeviceID),
		zap.String("sensor_type", string(data.SensorType)),
		zap.Float64("value", data.Value),
		zap.String("unit", data.Unit))

	return nil
}

// saveSensorDataImmediate ç«‹å³å†™å…¥å•æ¡ä¼ æ„Ÿå™¨æ•°æ®åˆ°æ•°æ®åº“
func (s *Service) saveSensorDataImmediate(data *models.SensorData) error {
	// ç›´æ¥å†™å…¥æ•°æ®åº“ï¼Œä¸ä½¿ç”¨æ‰¹é‡é€šé“
	query := `
		INSERT INTO sensor_data (device_id, sensor_type, value, unit, timestamp, quality, synced)
		VALUES (?, ?, ?, ?, ?, ?, ?)
	`

	_, err := s.db.Exec(query,
		data.DeviceID,
		data.SensorType,
		data.Value,
		data.Unit,
		data.Timestamp,
		data.Quality,
		data.Synced,
	)

	if err != nil {
		return fmt.Errorf("database insert failed: %w", err)
	}

	return nil
}

// SaveAlert ä¿å­˜å‘Šè­¦ä¿¡æ¯ï¼ˆMQTT è°ƒç”¨ï¼‰
func (s *Service) SaveAlert(mqttAlert interface{}) error {
	// ç±»å‹è½¬æ¢
	type mqttAlertData struct {
		DeviceID  string
		AlertType string
		Severity  string
		Message   string
		Value     float64
		Threshold float64
		Timestamp time.Time
	}

	jsonBytes, err := json.Marshal(mqttAlert)
	if err != nil {
		return fmt.Errorf("failed to marshal alert: %w", err)
	}

	var mqttA mqttAlertData
	if err := json.Unmarshal(jsonBytes, &mqttA); err != nil {
		return fmt.Errorf("failed to unmarshal alert: %w", err)
	}

	// è½¬æ¢ä¸º models.Alert
	valuePtr := mqttA.Value
	thresholdPtr := mqttA.Threshold
	alert := &models.Alert{
		DeviceID:  mqttA.DeviceID,
		AlertType: mqttA.AlertType,
		Severity:  mqttA.Severity,
		Message:   mqttA.Message,
		Value:     &valuePtr,
		Threshold: &thresholdPtr,
		Timestamp: mqttA.Timestamp,
		Resolved:  false,
	}

	// å‘é€åˆ°å‘Šè­¦é€šé“
	select {
	case s.alertChan <- alert:
		s.logger.Info("MQTT alert queued",
			zap.String("device_id", alert.DeviceID),
			zap.String("alert_type", alert.AlertType),
			zap.String("severity", alert.Severity))
		return nil
	default:
		return fmt.Errorf("alert channel full")
	}
}

// cleanupOldData å®šæ—¶æ¸…ç†æ—§æ•°æ®ï¼ˆé˜²æ­¢ç£ç›˜æ’‘çˆ†ï¼‰
func (s *Service) cleanupOldData() {
	defer s.wg.Done()

	// æ¯å¤©å‡Œæ™¨2ç‚¹æ¸…ç†ä¸€æ¬¡ï¼ˆ24å°æ—¶é—´éš”ï¼‰
	ticker := time.NewTicker(24 * time.Hour)
	defer ticker.Stop()

	// å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡æ¸…ç†
	s.performCleanup()

	for {
		select {
		case <-s.stopChan:
			s.logger.Info("æ•°æ®æ¸…ç†åç¨‹å·²åœæ­¢")
			return
		case <-ticker.C:
			s.performCleanup()
		}
	}
}

// performCleanup æ‰§è¡Œæ¸…ç†æ“ä½œ
func (s *Service) performCleanup() {
	// è®¡ç®—æˆªæ­¢æ—¶é—´ï¼ˆä¿ç•™æœ€è¿‘Nå¤©çš„æ•°æ®ï¼‰
	cutoffTime := time.Now().AddDate(0, 0, -s.retentionDays)

	s.logger.Info("ğŸ§¹ å¼€å§‹æ¸…ç†æ—§ä¼ æ„Ÿå™¨æ•°æ®",
		zap.Time("cutoff_time", cutoffTime),
		zap.Int("retention_days", s.retentionDays))

	// åˆ é™¤è¶…è¿‡ä¿ç•™æœŸçš„æ•°æ®
	query := `DELETE FROM sensor_data WHERE timestamp < ?`
	result, err := s.db.Exec(query, cutoffTime)
	if err != nil {
		s.logger.Error("âŒ æ¸…ç†æ—§æ•°æ®å¤±è´¥", zap.Error(err))
		return
	}

	rowsAffected, _ := result.RowsAffected()

	if rowsAffected > 0 {
		s.logger.Info("âœ… æ—§ä¼ æ„Ÿå™¨æ•°æ®æ¸…ç†å®Œæˆ",
			zap.Int64("deleted_rows", rowsAffected),
			zap.String("freed_space_estimate", fmt.Sprintf("~%.2f MB", float64(rowsAffected)*100/1024/1024)))

		// æ‰§è¡ŒVACUUMæ•´ç†æ•°æ®åº“ï¼Œå›æ”¶ç£ç›˜ç©ºé—´
		s.logger.Info("ğŸ”§ å¼€å§‹æ‰§è¡Œæ•°æ®åº“VACUUMï¼ˆå›æ”¶ç£ç›˜ç©ºé—´ï¼‰...")
		if _, err := s.db.Exec("VACUUM"); err != nil {
			s.logger.Error("âŒ æ•°æ®åº“VACUUMå¤±è´¥", zap.Error(err))
		} else {
			s.logger.Info("âœ… æ•°æ®åº“VACUUMå®Œæˆï¼Œç£ç›˜ç©ºé—´å·²å›æ”¶")
		}
	} else {
		s.logger.Info("â„¹ï¸  æ— éœ€æ¸…ç†ï¼Œæ²¡æœ‰è¶…è¿‡ä¿ç•™æœŸçš„æ•°æ®")
	}

	// åŒæ—¶æ¸…ç†æ—§çš„å‘Šè­¦è®°å½•
	alertQuery := `DELETE FROM alerts WHERE timestamp < ? AND resolved = 1`
	alertResult, err := s.db.Exec(alertQuery, cutoffTime)
	if err != nil {
		s.logger.Error("âŒ æ¸…ç†æ—§å‘Šè­¦å¤±è´¥", zap.Error(err))
	} else {
		alertRows, _ := alertResult.RowsAffected()
		if alertRows > 0 {
			s.logger.Info("âœ… æ—§å‘Šè­¦è®°å½•æ¸…ç†å®Œæˆ",
				zap.Int64("deleted_alerts", alertRows))
		}
	}
}
